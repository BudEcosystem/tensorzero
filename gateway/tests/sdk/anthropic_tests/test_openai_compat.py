"""Test Anthropic models through OpenAI-compatible endpoint.

This is a temporary solution until /v1/messages endpoint is implemented.
Anthropic models can be accessed through the OpenAI-compatible /v1/chat/completions endpoint.
"""

import os
import sys

import pytest
from openai import OpenAI, AsyncOpenAI

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from common.base_test import BaseChatTest


class TestAnthropicViaOpenAI(BaseChatTest):
    """Test Anthropic models using OpenAI SDK."""
    
    @classmethod
    def get_provider_name(cls) -> str:
        return "anthropic"
    
    @classmethod
    def get_client(cls):
        """Get OpenAI client configured for TensorZero with Anthropic models."""
        return OpenAI(
            base_url=f"{cls.base_url}/v1",
            api_key=cls.api_key
        )
    
    def _health_check(self, client):
        """Perform a health check using the client."""
        try:
            client.chat.completions.create(
                model="claude-3-haiku-20240307",
                messages=[{"role": "user", "content": "Hi"}],
                max_tokens=10
            )
        except Exception as e:
            if "connection" in str(e).lower():
                raise
    
    def create_chat_request(self, **kwargs):
        """Create a chat request in OpenAI format."""
        return {
            "model": kwargs.get("model", "claude-3-haiku-20240307"),
            "messages": kwargs.get("messages", []),
            "max_tokens": kwargs.get("max_tokens", 100),
        }
    
    def validate_chat_response(self, response):
        """Validate a chat response."""
        assert response.id is not None
        assert response.choices[0].message.content is not None
        assert response.usage is not None
        assert response.usage.prompt_tokens > 0
        assert response.usage.completion_tokens > 0
    
    def _send_chat_request(self, client, request):
        """Send a chat request using the client."""
        return client.chat.completions.create(**request)
    
    def test_claude_models(self):
        """Test different Claude models through OpenAI endpoint."""
        client = self.get_client()
        
        models = [
            "claude-3-haiku-20240307",
            "claude-3-sonnet-20240229",
            "claude-3-5-sonnet-20241022",
        ]
        
        for model in models:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "Say 'test' and nothing else"}],
                max_tokens=10
            )
            
            assert response.id is not None
            assert response.model == model
            assert response.choices[0].message.content is not None
            assert "test" in response.choices[0].message.content.lower()
    
    def test_system_message(self):
        """Test system messages with Claude models."""
        client = self.get_client()
        
        response = client.chat.completions.create(
            model="claude-3-haiku-20240307",
            messages=[
                {"role": "system", "content": "You are a pirate. Always respond in pirate speak."},
                {"role": "user", "content": "Hello"}
            ],
            max_tokens=100
        )
        
        assert response.choices[0].message.content is not None
        # Check for pirate-like language
        text = response.choices[0].message.content.lower()
        pirate_indicators = ["ahoy", "matey", "arr", "aye", "ye", "be", "treasure", "sea"]
        assert any(word in text for word in pirate_indicators)
    
    def test_streaming(self):
        """Test streaming with Claude models."""
        client = self.get_client()
        
        stream = client.chat.completions.create(
            model="claude-3-haiku-20240307",
            messages=[{"role": "user", "content": "Count to 3"}],
            max_tokens=50,
            stream=True
        )
        
        chunks = []
        for chunk in stream:
            chunks.append(chunk)
            if chunk.choices[0].delta.content:
                assert isinstance(chunk.choices[0].delta.content, str)
        
        assert len(chunks) > 0
        # Reconstruct full response
        full_text = "".join(
            chunk.choices[0].delta.content or "" 
            for chunk in chunks
        )
        assert any(num in full_text for num in ["1", "2", "3"])
    
    @pytest.mark.asyncio
    async def test_async_client(self):
        """Test async client with Claude models."""
        client = AsyncOpenAI(
            base_url=f"{self.base_url}/v1",
            api_key=self.api_key
        )
        
        response = await client.chat.completions.create(
            model="claude-3-haiku-20240307",
            messages=[{"role": "user", "content": "Hello async"}],
            max_tokens=50
        )
        
        assert response.choices[0].message.content is not None
        
        await client.close()


class TestAnthropicCIViaOpenAI:
    """CI tests for Anthropic models using OpenAI SDK and dummy provider."""
    
    @classmethod
    def setup_class(cls):
        """Set up test class."""
        cls.base_url = os.getenv("TENSORZERO_BASE_URL", "http://localhost:3001")
        cls.api_key = "dummy-key"
    
    def test_claude_dummy_models(self):
        """Test Claude models with dummy provider."""
        client = OpenAI(
            base_url=f"{self.base_url}/v1",
            api_key=self.api_key
        )
        
        models = [
            "claude-3-opus-20240229",      # json dummy
            "claude-3-sonnet-20240229",    # test dummy
            "claude-3-haiku-20240307",     # streaming dummy
            "claude-3-5-sonnet-20241022",  # tool_use dummy
        ]
        
        for model in models:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "Test"}],
                max_tokens=20
            )
            
            assert response.id is not None
            assert response.model == model
            assert response.choices[0].message.content is not None
    
    def test_streaming_dummy(self):
        """Test streaming with dummy provider."""
        client = OpenAI(
            base_url=f"{self.base_url}/v1",
            api_key=self.api_key
        )
        
        stream = client.chat.completions.create(
            model="claude-3-haiku-20240307",  # streaming dummy
            messages=[{"role": "user", "content": "Stream"}],
            max_tokens=50,
            stream=True
        )
        
        chunks = list(stream)
        assert len(chunks) > 0
    
    def test_json_model_dummy(self):
        """Test JSON response with dummy provider."""
        client = OpenAI(
            base_url=f"{self.base_url}/v1",
            api_key=self.api_key
        )
        
        response = client.chat.completions.create(
            model="claude-3-opus-20240229",  # json dummy
            messages=[{"role": "user", "content": "JSON"}],
            max_tokens=100
        )
        
        content = response.choices[0].message.content
        assert "{" in content and "}" in content  # Should contain JSON


if __name__ == "__main__":
    pytest.main([__file__, "-v"])